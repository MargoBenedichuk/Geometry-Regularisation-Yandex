# Исследование топологии латентного пространства CNN с использованием регуляризации
Этот проект посвящён классификации изображений с использованием усовершенствованных методов регуляризации, учитывающих геометрические и геодезические свойства признакового пространства. В дополнение к стандартной функции потерь (кросс-энтропии) в обучение включаются специальные регуляризационные компоненты, которые направляют модель к формированию «правильно» организованного латентного пространства признаков. Проще говоря, нейросеть не только учится правильно классифицировать, но и структурировать свои скрытые представления с учётом геометрии данных:
    • Геометрическая регуляризация: поощряет локальную геометрию в латентном пространстве – например, сохранение определённых свойств манифолда (многообразия) данных, таких как кластерная структура или локальная размерность признаков. Добавляя к функции потерь штраф за отклонения, этот метод поддерживает «правильную форму» пространства признаков, что может улучшить обобщающую способность модели и интерпретируемость эмбеддингов.
    • Геодезическая регуляризация: поощряет соответствие расстояний вдоль манифолда (геодезических расстояний между точками в латентном пространстве) их прямым евклидовым расстояниям. Идея заключается в «выпрямлении» пространства эмбеддингов: регуляризатор стремится сделать отношение геодезического расстояния к евклидову близким к 1.0. Значение 1.0 означает, что многомерное пространство признаков практически плоское (без искажений). Штрафуя отклонения этого отношения от единицы, модель формирует латентное пространство ближе к евклидовой структуре, одновременно сохраняя внутреннюю геометрию данных.
Проект предоставляет экспериментальную платформу для сравнения базового классификатора (обученного только с кросс-энтропийной потерей) с классификаторами, в обучение которых включены описанные регуляризационные термы. Цель — продемонстрировать, как геометрическая и геодезическая регуляризация влияют на качество модели и структуру полученных признаковых представлений. Сравнение проводится с помощью количественных метрик и визуализации латентного пространства.
## Структура репозитория
Проект организован по модулям и конфигурационным файлам для удобства проведения экспериментов. Ключевые файлы и каталоги:
    • **main_pipeline_experiment.py **— основной скрипт для запуска эксперимента. Выполняет обучение модели в двух режимах: с включённым геодезическим регуляризатором и базовом (без дополнительной регуляризации). Скрипт автоматически тренирует модель в обоих вариантах, а затем сохраняет и выводит сравнительный анализ результатов (метрики, графики и пр.). Предназначен для единичного запуска с непосредственным сравнением «регуляризация vs. без регуляризации».
    • ** grid_parameters_experiment_runner.py ** — скрипт для серийного запуска множества экспериментов (грид-поиск по параметрам). Позволяет перебрать комбинации гиперпараметров, таких как разные датасеты, архитектуры моделей, начальные генераторы случайности (seed) и типы регуляризации. Скрипт генерирует YAML-конфигурации для каждой комбинации и поочерёдно (или параллельно) запускает их. Таким образом можно систематически оценить влияние регуляризации, например, сравнить эффект на MNIST vs. CIFAR-10, или на простой CNN vs. ResNet.
    • ** src/ **— основная директория с исходным кодом, содержащая реализованные модули:
    • ** datasets/ **— загрузка и предобработка датасетов. Содержит код для получения стандартных наборов данных (MNIST, CIFAR-10 и т.д.), их скачивания при необходимости, разбиения на обучающую/валидационную выборки и применения трансформаций (нормализация, аугментация и пр.).
    •**  models/** — определения моделей. Содержит реализации архитектур нейросетей, например, простая свёрточная сеть (SimpleCNN) для небольших изображений или фабрики для создания моделей ResNet и других. Здесь определяется структура модели (слои, размерности и пр.).
    • ** metrics/ **— вычисление метрик качества. Включает стандартные метрики классификации (точность, матрица ошибок и т.п.), а также специальные метрики для оценки геометрии латентного пространства (функции для расчёта геодезических расстояний, локальной размерности, индекса силуэта кластеров эмбеддингов и др.).
    • **regularization/** — реализация регуляризационных потерь. Здесь находятся, например, geodesic_loss.py (вычисление штрафа на основе геодезических расстояний) и geometry_mark_loss.py (вычисление штрафа за отклонение геометрических свойств). Эти модули подключаются во время обучения, добавляя дополнительное регуляризационное слагаемое к общей функции потерь.
    • **visualization/** — утилиты для визуализации результатов. Содержит функции для построения графиков и проекций латентного пространства, например 2D-проекции эмбеддингов с помощью UMAP, возможно генерацию интерактивных визуализаций распределения признаков по классам.
    • **utils/** — вспомогательные утилиты. Здесь находятся, например, функции для загрузки конфигураций, реестр (registry.py) для сопоставления строковых идентификаторов с объектами (например, название датасета → функция его загрузки), и другие общие функции, используемые в проекте.
    • **configs/** — каталог YAML-файлов конфигураций экспериментов. Каждый конфиг описывает полный набор параметров для запуска: выбор датасета, модели, гиперпараметры обучения, тип регуляризации и связанные настройки. Например, config_with_geodesic.yaml включает геодезический регуляризатор, а config_without_regularization.yaml задаёт базовый вариант без дополнительной регуляризации. Имеется файл по умолчанию (например, defaults.yaml), задающий стандартные настройки, от которых можно отталкиваться в отдельных конфигурациях.
    • **experiments_result/** — каталог для сохранения результатов экспериментов. При каждом запуске здесь создаётся новая папка с артефактами конкретного эксперимента. Структура именования может включать параметры эксперимента или время запуска. Например, для грид-поиска результаты могут раскладываться по подпапкам: experiments_result/<dataset>/<model>/seed_<N>/<regularizer>/ для каждой комбинации. При единичном запуске скриптом основного pipeline создаётся папка (например, experiments_result/exp_<timestamp>/), содержащая вложенные директории с результатами регуляризованного и базового прогона, а также отчёт сравнения. Такое разбиение упорядочивает результаты и облегчает их анализ.
Запуск экспериментов
Проект предусматривает два основных способа запуска экспериментов из командной строки:
    • **Однократный эксперимент (main_pipeline_experiment.py):** запуск единичного эксперимента (либо парного прогона для сравнения) на базе одного конфигурационного файла. Использование: python main_pipeline_experiment.py <config_path> <output_dir>. В аргументах указывается путь до YAML-конфигурации (<config_path>, например, файл в configs/) и желаемая директория для сохранения результатов (<output_dir>). Скрипт тренирует модель согласно параметрам, заданным в конфиге, и автоматически включает дополнительный запуск для базовой версии без регуляризации, если в конфиге активирован регуляризатор. Все результаты (метрики, модели, графики) сохраняются под указанной директорией. По окончании работы вы получите вывод ключевых метрик в консоли и полный набор сохранённых артефактов для анализа.
    •** Серийный запуск (грид-поиск) (grid_parameters_experiment_runner.py):** запуск серии экспериментов по заранее заданной решётке параметров. Этот скрипт можно запустить без аргументов: python grid_parameters_experiment_runner.py. Внутри него определён список вариантов для перебора (наборы данных, типы моделей, значения сидов, варианты регуляризации и т.д.). По умолчанию покрывается определённый набор комбинаций, однако при необходимости параметры перебора можно отредактировать в коде скрипта. При запуске для каждой комбинации создаётся соответствующий конфигурационный файл (автоматически, на основе шаблона), после чего эксперименты выполняются последовательно (либо параллельно, если так настроено). Результаты каждого прогона сохраняются в структуре папок внутри experiments_result/ (по схеме, описанной выше). Скрипт также ведёт файл реестра experiment_registry.json в директории результатов, отмечая выполнение каждой комбинации. Это позволяет прерывать и возобновлять длительный грид-поиск: при повторном запуске уже завершённые комбинации пропускаются.
Конфигурация экспериментов
Гибкость экспериментов обеспечивается YAML-файлами конфигураций (в каталоге configs/), которые позволяют задавать все аспекты обучения без изменения кода. Основные разделы типичной конфигурации:
    • **Датасет:** параметры выборки данных. Указывается название набора (name, например "mnist" или "cifar10"), путь к данным (root, например ./data), доля данных для валидации (val_ratio, например 0.2 для 20% валвыборки). Также можно задать преобразования (transform) — либо null для использования преобразований по умолчанию, либо ссылку на функцию предобработки (например, src.utils.registry.get_mnist), которая будет вызвана для получения объекта датасета. Такой подход через реестр функций позволяет гибко подключать разные датасеты через конфиг.
    •** Модель:** настройки нейросетевой модели. Определяется тип/архитектура модели (type или name, например "simple_cnn" для простой сверточной сети или "resnet50" для ResNet-50). Указываются характерные параметры: размер входного тензора (input_shape, например [1,28,28] для одноканальных 28×28 изображений MNIST), размерность скрытого представления (hidden_dim, число нейронов в последнем скрытом слое или embedding-размер), число классов (num_classes, например 10 для MNIST или CIFAR-10), а также тип классификационной головы (head_type, например "linear" для простого полносвязного выхода или "mlp" для многослойного перцептрона на выходе). Эти параметры используются фабрикой моделей для построения нужной архитектуры.
    • **Обучение:** гиперпараметры процесса обучения. Сюда относятся размер батча (batch_size), число эпох (epochs) и скорость обучения (lr – learning rate). Опционально могут быть и другие параметры (например, выбор оптимизатора), но в данной кодовой базе основные настройки обучения выносятся в эти поля.
    • **Регуляризация:** ключевой для проекта раздел, задающий использование геометрических/геодезических регуляризаторов. Здесь определяется тип регуляризации и её параметры:
    • **name:** тип регуляризатора, например "geodesic" (геодезическая), "geometry" (геометрическая), "combined" (оба вида одновременно) или "none" (без регуляризации). Значение "none" используется для контрольных прогонов без регуляризатора.
    • **enabled:** флаг включения (True/False), позволяющий явно отключать или включать дополнительную регуляризацию. В ряде случаев достаточно указать name: "none", но наличие явного флага упрощает логику.
    • **weight:** весовой коэффициент при регуляризационном слагаемом в общей функции потерь. Итоговая функция обычно определяется как Loss = CrossEntropy_loss + weight * Regularizer_loss. Например, weight: 1.0 означает, что регуляризация добавляется в полную силу; можно уменьшать этот коэффициент для ослабления влияния регуляризатора.
    •** Параметры конкретного регуляризатора**: при выборе определённого типа регуляризации конфиг включает под-раздел с его параметрами. Например, для геодезического регуляризатора (часто реализованного как поддержание отношения геодезического расстояния к евклидову) могут быть указаны:
        ◦ **lambda_reg**– базовый коэффициент регуляризации (будет умножен на общий weight), определяющий силу штрафа за нарушение геодезического свойства.
        ◦ **target_ratio** – целевое отношение геодезического расстояния к евклидовому (как правило, 1.0 для стремления к «плоскому» латентному пространству).
        ◦ **n_neighbors** – число соседей в k-NN графе, используемом для вычисления геодезических расстояний на манифолде (например, 5, 10 или 15; по умолчанию часто 10).
        ◦ Дополнительные опции могут задавать, с какого момента или как часто применять регуляризацию (например, начать со 2-й эпохи или применять через определённое число итераций), чтобы постепенно вводить эффект регуляризатора.
Аналогично, для геометрической регуляризации конфигурация может иметь свои параметры (например, связанные с локальной размерностью или плотностью распределения). Указав name: "none" или enabled: false, можно полностью отключить дополнительный регуляризатор и получить чисто базовое обучение.
    • **Логирование и вывод:** настройки того, какие результаты собирать и сохранять. Конфигурация позволяет указать, какие метрики вычислять на обучающей и валидационной выборках (metrics – списки метрик для train и val), нужно ли вычислять показатели по эмбеддингам (embedding_metrics, которые могут быть отключены или запускаться раз в N эпох). Также задаются параметры сохранения: нужно ли сохранять итоговые метрики (save_metrics), латентные представления модели (save_latents), UMAP-график распределения эмбеддингов (save_umap), и указывается базовый путь для выходных данных (output.dir). В конфигурации по умолчанию (или в сгенерированных файлах для грид-поиска) выходной каталог часто формируется автоматически на основе параметров эксперимента.
Результаты экспериментов
Каждый запуск эксперимента сохраняет разнообразные выходные данные (артефакты) в соответствующей папке внутри experiments_result/. Основные результаты включают:
    • **Метрики и история обучения:** Итоговые численные метрики классификации на валидационном наборе сохраняются в JSON-файле (например, metrics.json). Там можно найти, в частности, финальную точность модели, а также при необходимости другие показатели (точность, полнота, F1-score по классам и т.д.). Кроме того, сохраняется история обучения в виде JSON (training_history.json), содержащего значения метрик (потери, точности, и при включенной регуляризации – значения регуляризационной потери) на каждой эпохе. Это позволяет строить графики обучения и анализировать динамику сходимости или переобучения.
    • **Эмбеддинги и их визуализация:** Поскольку проект ориентирован на изучение латентного пространства, сохраняются артефакты, связанные с эмбеддингами модели. Во-первых, финальные скрытые представления (латентные векторы) и соответствующие им метки классов сохраняются в файл (например, latents.npz – numpy-архив с массивами). Это даёт возможность впоследствии проанализировать распределение признаков, выполнить произвольные вычисления или визуализации. Во-вторых, автоматически генерируется двумерная проекция эмбеддингов с помощью UMAP – статичный график (PNG-изображение, например umap.png), на котором каждая точка представляет образ выборки в пространстве признаков (обычно точки раскрашены по классам, что позволяет оценить, насколько хорошо разделились кластеры разных классов). Также может сохраняться интерактивная визуализация (HTML-файл), позволяющая детально рассмотреть распределение эмбеддингов (увеличивать, наводить на точки и т.п.) – для технического анализа это необязательно, но может быть полезно.
    • **Геометрические показатели латентного пространства:** В дополнение к стандартным метрикам, при использовании регуляризации рассчитываются специальные показатели, характеризующие геометрию и структуру пространства признаков. Они сохраняются в отдельных JSON-файлах. Например, geometry_summary.json может содержать среднюю локальную размерность кластеров эмбеддингов и индекс силуэта, оценивающий качество кластеризации латентных представлений (значение близкое к 1 означает хорошо разделённые кластеры). Файл geodesic_summary.json содержит статистику по геодезическим расстояниям на манифолде – например, среднее и стандартное отклонение отношения геодезического расстояния к евклидову по множеству пар точек. Такие показатели (иногда агрегируются в понятия вроде «flatness score» или «quality score») дают количественную оценку того, насколько «плоским» получилось латентное пространство и насколько оно сохраняет структуру классов.
    • **Графики обучения:** Для наглядности скрипт может сохранять графики процесса обучения. Например, train_val_loss.png – график изменения функции потерь на обучающей и валидационной выборках по эпохам, а train_val_accuracy.png – график точности модели на обучении и валидации по эпохам. Эти графики позволяют быстро оценить сходимость модели, появление переобучения (если кривая ошибки на валидации начинает расти) и общее поведение обучения с и без регуляризации.
    • **Отчёт по классификации:** По завершении обучения на валидационном наборе генерируется подробный отчёт (например, classification_report.json), содержащий метрики классификации по каждому классу – точность (precision), полноту (recall) и F1-score, а также сводные показатели. Этот отчёт помогает выявить, на каких классах модель ошибается больше всего, и сравнить баланс качества между классами.
    • **Сравнительный отчёт (для парного запуска):** Если эксперимент проводился в режиме сравнения (как в main_pipeline_experiment.py, где выполняются два прогона – с регуляризацией и без), дополнительно сохраняется сравнительный отчёт результатов. Например, comparison_report.json содержит прямое сопоставление метрик «С регуляризацией» vs «Без регуляризации»: итоговые значения точности, потерь и других метрик для обеих моделей, разницу между ними в абсолютном и процентном выражении, сравнение геометрических показателей (например, разница в локальной размерности или индексе силуэта) и сравнение геодезических показателей (насколько «плоским» стало пространство в каждом случае). Также анализируются динамические характеристики обучения – например, итоговые значения функции потерь на обучении и валидации, разница между ними как оценка переобучения. В дополнение к JSON-отчёту, скрипт генерирует наглядный график сравнительных кривых обучения training_curves_comparison.png, где на одном поле изображены кривые потерь для обоих запусков. Это позволяет визуально оценить, как регуляризация повлияла на процесс обучения (например, уменьшился ли разрыв между трейнингом и валидацией, изменилась ли скорость сходимости и т.д.).
    
Все перечисленные артефакты сохраняются автоматически в ходе работы скриптов. Таким образом, технический специалист может после выполнения эксперимента загрузить нужные файлы и тщательно проанализировать влияние геометрической и геодезической регуляризации на модель, не внося изменений в код. Интеграция с системами логирования (например, MLflow) предусмотрена конфигурацией, но для обзора результатов достаточно изучить сохранённые файлы в experiments_result/. Выводы экспериментов – как количественные метрики, так и визуальные представления – дают целостную картину того, как дополнительная регуляризация отражается на качестве классификации и структуре латентного пространства модели.
